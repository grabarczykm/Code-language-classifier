{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Programming language classification model__\n",
    "\n",
    "The point of this program is to identyfy the programming language of delivered code.\n",
    "Classyfying model uses __Naive Bayes classifier__.\n",
    "\n",
    "Programing languages' codes used in training data: (JavaScript, Swift, Python, Java, C++, Ruby, Rust, C, Scala, R, Go, Mathematica, Kotlin, Fortran, Julia,PHP, Matlab, haskell, perl)\n",
    "\n",
    "Program can be splited for two parts:\n",
    "1. Handling and cleanin training data, stored in CSV file\n",
    "2. Calculations based on Naive Bayes classifier\n",
    "\n",
    "To run this model,  paste the test code to file \"test_data.txt\" and run all cells from top to the bottom.\n",
    "After you once run all cells, only change code in \"test_data.txt\" and run last cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Inner functions__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Prepering the training data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_rows(rows):\n",
    "    \n",
    "    \"\"\" Preliminary data cleanin. Preparing the data set to split for particular languages\"\"\"\n",
    "        \n",
    "    #Deleting semicolons\n",
    "    rows = [x.replace(';', '') for row in rows for x in row] \n",
    "    \n",
    "    #Deleting new line sign \n",
    "    rows = list(map(lambda s: s.strip(), rows)) \n",
    "    \n",
    "    #All lower case\n",
    "    rows = list(map(lambda s: s.lower(), rows)) \n",
    "    \n",
    "    return(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lang_range(rows,prog_lang_loc):\n",
    "    \n",
    "    \"\"\" Preparing the list of ranges taken by each language in training data list \"\"\"\n",
    "    \n",
    "    index_list = []\n",
    "    for lang in prog_lang_loc:\n",
    "        for row in rows:\n",
    "            if lang in row:\n",
    "                index_list.append(rows.index(row))\n",
    "                break\n",
    "    \n",
    "    return(index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_dictionary(rows, index_list, langs):\n",
    "    \n",
    "    \"\"\" Preparing the dictionary of programming languages and codes \"\"\"\n",
    "    \n",
    "    train_dict = {} # dictionary for training classifier\n",
    "\n",
    "    for lang in langs:\n",
    "        if langs.index(lang) < len(langs) - 1: \n",
    "            train_dict[lang] = rows[index_list[langs.index(lang)]:index_list[langs.index(lang) + 1]]\n",
    "        else:\n",
    "            train_dict[lang] = rows[index_list[langs.index(lang)]:]                   \n",
    "            \n",
    "    return(train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_dict(train_dict,langs):\n",
    "    \n",
    "    \"\"\" Clearing the training dictionary. Deleting punctuation, numbers, empty elemets in list. Spliting elements for words\"\"\"\n",
    "    \n",
    "    for lang in langs:\n",
    "        \n",
    "        #Deleting punctuation and characters\n",
    "        translator=str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "        train_dict[lang] = list(map(lambda row: row.translate(translator), train_dict[lang]))\n",
    "        \n",
    "        #Spliting elements for words \n",
    "        words = []\n",
    "        for element in train_dict[lang]:\n",
    "            words.extend(element.split())\n",
    "            \n",
    "        train_dict[lang] = words\n",
    "        \n",
    "        #Deleting numbers\n",
    "        train_dict[lang] = [element for element in train_dict[lang] if element.isalpha()]\n",
    "        \n",
    "        #Deleting one-sign elements\n",
    "        train_dict[lang] = [element for element in train_dict[lang] if len(element)>1]\n",
    "        \n",
    "        \n",
    "    return(train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lenght_correction(train_dict,langs):\n",
    "    \n",
    "    \"\"\" Because of great differences in number of codes for each leanguage this function is \n",
    "    responsible for equalizing the lenght of data\"\"\"\n",
    "    \n",
    "    lang_check = {}\n",
    "    for lang in langs:\n",
    "        lang_check[lang] = len(train_dict[lang])\n",
    "            \n",
    "    # Checking the number of elemnts attached to each language\n",
    "    check_list = sorted(lang_check.values())\n",
    "    \n",
    "    # Reduction of data to the lowest number\n",
    "    for lang in langs:\n",
    "        train_dict[lang] = train_dict[lang][:check_list[0]]\n",
    "        \n",
    "    return(train_dict)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Prepering the test data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_the_file(filename):\n",
    "    \n",
    "    \"\"\" Reading the test file \"\"\"\n",
    "    \n",
    "    file_object = open(filename, 'r')\n",
    "    words = file_object.read().split()\n",
    "    words = clear_the_file(words)\n",
    "    \n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_the_file(words):\n",
    "    \n",
    "    \"\"\" Clearing test file. Same standard as training data\"\"\"\n",
    "    \n",
    "    #All lower case \n",
    "    words = list(map(lambda s: s.lower(), words)) \n",
    "    \n",
    "    #Deleting punctuation\n",
    "    translator=str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "    words = list(map(lambda word: word.translate(translator), words))\n",
    "    \n",
    "    #Spliting elements for single words\n",
    "    words2 = []\n",
    "    for word in words:\n",
    "        words2.extend(word.split())\n",
    "    \n",
    "    words = words2\n",
    "    \n",
    "    #Deleting numbers\n",
    "    words = [word for word in words if word.isalpha()]\n",
    "    \n",
    "    #Deleting one-sign elements\n",
    "    words = [word for word in words if len(word)>1]\n",
    "    \n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Calculations__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_the_classifier(train_dict, langs):\n",
    "    \n",
    "    \"\"\" Model training \"\"\"\n",
    "    \n",
    "    #Summary of each word used in each language\n",
    "    trained_data = {}\n",
    "    \n",
    "    #Summary of each word used in any language\n",
    "    all_words = Counter()\n",
    "    \n",
    "    #Train the model\n",
    "    for lang in langs:\n",
    "        trained_data[lang] = {}\n",
    "        for word in train_dict[lang]:\n",
    "            if word in trained_data[lang]:\n",
    "                trained_data[lang][word] +=1\n",
    "            else:\n",
    "                trained_data[lang][word] = 1 \n",
    "            all_words[word] += 1\n",
    "            \n",
    "    return(trained_data, all_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prob(lang, code, trained_data, all_words ):\n",
    "    \n",
    "    \"\"\" Calculating probability for language \"\"\"\n",
    "    prob = 0.0\n",
    "    for word in code:\n",
    "        \n",
    "        #If word is contained in language training_dict\n",
    "        try:\n",
    "            if prob == 0.0:\n",
    "                prob = trained_data[lang][word]/all_words[word]\n",
    "            else:\n",
    "                prob = prob * trained_data[lang][word]/all_words[word]\n",
    "        except(KeyError):\n",
    "            \n",
    "            #If word is contained in all_words list \n",
    "            if word in all_words:\n",
    "                prob = prob * (1/all_words[word])\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "    return(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_prob(trained_data, all_words, code, langs):\n",
    "    \n",
    "    \"\"\" Predicting the programing language \"\"\"\n",
    "    \n",
    "    lang_chance = {}\n",
    "    \n",
    "    for lang in langs:\n",
    "        prob = calc_prob(lang, code, trained_data, all_words )\n",
    "        lang_chance[lang] = prob\n",
    "        \n",
    "    print(lang_chance)\n",
    "    return('Hopefully programming language is ' + max(lang_chance, key=lang_chance.get))\n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Imports and loading the training data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, string,math\n",
    "from collections import Counter\n",
    "\n",
    "filename = 'data.csv'\n",
    "\n",
    "rows = []\n",
    "prog_lang_loc = ['javascript,10001','swift,10475','python,10750','java,11462','c++,12090','ruby,12631','rust,13303','c,13624','scala,14288','r,14819','go,15192','mathematica,15859','kotlin,16489','fortran,17106','julia,17565','php,18026','matlab,18380','haskell,18711','perl,19360']\n",
    "langs = ['javascript','swift','python','java','c++','ruby','rust','c','scala','r','go','mathematica','kotlin','fortran','julia','php','matlab','haskell','perl']\n",
    "\n",
    "with open(filename, 'r', encoding=\"utf8\") as csvfile:\n",
    "    \n",
    "    csvreader = csv.reader(csvfile)\n",
    "    \n",
    "    for row in csvreader:\n",
    "        rows.append(row)\n",
    "\n",
    "rows = clear_rows(rows)\n",
    "index_list = lang_range(rows,prog_lang_loc)\n",
    "train_dict = training_dictionary(rows, index_list, langs)\n",
    "train_dict = clear_dict(train_dict,langs)\n",
    "train_dict = lenght_correction(train_dict,langs)\n",
    "trained_data, all_words = train_the_classifier(train_dict, langs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Run ONLY  this part__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'javascript': 1.2507743666739968e-37, 'swift': 1.2453718801516847e-37, 'python': 7.980857348209553e-30, 'java': 3.409624525924143e-43, 'c++': 8.510522148184023e-40, 'ruby': 1.3472277291133397e-38, 'rust': 2.4073014451496573e-40, 'c': 1.2765341344775553e-42, 'scala': 2.3922597994212834e-39, 'r': 3.892326814097173e-34, 'go': 4.3642861261119365e-39, 'mathematica': 2.3299372368441483e-34, 'kotlin': 1.8364170335770386e-36, 'fortran': 5.427751526863307e-43, 'julia': 3.063402424498982e-39, 'php': 9.806807683199635e-36, 'matlab': 3.473370965487525e-45, 'haskell': 1.1547614459632093e-40, 'perl': 4.1117425974589356e-36}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hopefully programming language is python'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'test_data.txt'#enter here te file name (test_data.txt)\n",
    "code = read_the_file(filename)\n",
    "\n",
    "language_prob(trained_data, all_words, code, langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
