{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, string, math, re \n",
    "from collections import Counter\n",
    "\n",
    "filename = 'data.csv'\n",
    "\n",
    "rows = []\n",
    "prog_lang_loc = ['javascript,10001','swift,10475','python,10750','java,11462','c++,12090','ruby,12631','rust,13303','c,13624','scala,14288','r,14819','go,15192','mathematica,15859','kotlin,16489','fortran,17106','julia,17565','php,18026','matlab,18380','haskell,18711','perl,19360']\n",
    "langs = ['javascript','swift','python','java','c++','ruby','rust','c','scala','r','go','mathematica','kotlin','fortran','julia','php','matlab','haskell','perl']\n",
    "\n",
    "with open(filename, 'r', encoding=\"utf8\") as csvfile:\n",
    "    \n",
    "    csvreader = csv.reader(csvfile)\n",
    "    \n",
    "    for row in csvreader:\n",
    "        rows.append(row)\n",
    "\n",
    "rows = clear_rows(rows)\n",
    "index_list = lang_range(rows,prog_lang_loc)\n",
    "train_dict = training_dictionary(rows, index_list, langs)\n",
    "train_dict = clear_dict(train_dict,langs)\n",
    "trained_data, all_words = train_the_classifier(train_dict, langs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_rows(rows):\n",
    "    \n",
    "    \"\"\"Wstępne oczyszczenie danych, przygotowanie do podzielenia danych na poszczególne języki programowania\"\"\"\n",
    "    \n",
    "    rows = [x.replace(';', '') for row in rows for x in row] #usunięcie znaków średnika\n",
    "    rows = list(map(lambda s: s.strip(), rows)) #usunięcie znaków nowego wiersza \n",
    "    rows = list(map(lambda s: s.lower(), rows)) #małe litery\n",
    "    \n",
    "    return(rows)\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lang_range(rows,prog_lang_loc):\n",
    "    \n",
    "    \"\"\" Utworzenie zakresów zajmowanych przez poszczególne języki w zestawie danych \"\"\"\n",
    "    \n",
    "    index_list = []\n",
    "    for lang in prog_lang_loc:\n",
    "        for row in rows:\n",
    "            if lang in row:\n",
    "                index_list.append(cleared_rows.index(row))\n",
    "                break\n",
    "    \n",
    "    return(index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_dictionary(rows, index_list, langs):\n",
    "    \n",
    "    \"\"\" Utworzenie słownika języków programowania i przypisanych im kodów \"\"\"\n",
    "    \n",
    "    train_dict = {} # słownik treningowy\n",
    "\n",
    "    for lang in langs:\n",
    "        if langs.index(lang) < len(langs) - 1: \n",
    "            train_dict[lang] = rows[index_list[langs.index(lang)]:index_list[langs.index(lang) + 1]]\n",
    "        else:\n",
    "            train_dict[lang] = rows[index_list[langs.index(lang)]:]\n",
    "            \n",
    "    return(train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_dict(train_dict,langs):\n",
    "    \n",
    "    for lang in langs:\n",
    "        \n",
    "        #Usunięcie interpunkcji i wszystkich znaków\n",
    "        translator=str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "        train_dict[lang] = list(map(lambda row: row.translate(translator), train_dict[lang]))\n",
    "        \n",
    "        #Rodzielenie elementów na pojedyncze słowa\n",
    "        words = []\n",
    "        for element in train_dict[lang]:\n",
    "            words.extend(element.split())\n",
    "            \n",
    "        train_dict[lang] = words\n",
    "        \n",
    "        #Usunięcie liczb\n",
    "        train_dict[lang] = [element for element in train_dict[lang] if element.isalpha()]\n",
    "        \n",
    "        #Usunięcie elementów jednoznakowych\n",
    "        train_dict[lang] = [element for element in train_dict[lang] if len(element)>1]\n",
    "        \n",
    "    return(train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_the_classifier(train_dict, langs):\n",
    "    \n",
    "    #Summary of each word used in each language\n",
    "    trained_data = {}\n",
    "    \n",
    "    #Summary of each word used in any language\n",
    "    all_words = Counter()\n",
    "    \n",
    "    #Train the model\n",
    "    for lang in langs:\n",
    "        trained_data[lang] = {}\n",
    "        for word in train_dict[lang]:\n",
    "            if word in trained_data[lang]:\n",
    "                trained_data[lang][word] +=1\n",
    "            else:\n",
    "                trained_data[lang][word] = 1 \n",
    "            all_words[word] += 1\n",
    "\n",
    "    return(trained_data, all_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_the_file(filename):\n",
    "    file_object = open(filename, 'r')\n",
    "    words = file_object.read().split()\n",
    "    words = clear_the_file(words)\n",
    "    \n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_the_file(words):\n",
    "\n",
    "    words = list(map(lambda s: s.lower(), words)) #Małe litery\n",
    "    \n",
    "    translator=str.maketrans(string.punctuation, ' '*len(string.punctuation))#Usunięcie interpunkcji\n",
    "    words = list(map(lambda word: word.translate(translator), words))\n",
    "    \n",
    "    #Rodzielenie elementów na pojedyncze słowa\n",
    "    words2 = []\n",
    "    for word in words:\n",
    "        words2.extend(word.split())\n",
    "    \n",
    "    words = words2\n",
    "    \n",
    "    #Usunięcie liczb\n",
    "    words = [word for word in words if word.isalpha()]\n",
    "    \n",
    "    #Usunięcie elementów jednoznakowych\n",
    "    words = [word for word in words if len(word)>1]\n",
    "    \n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prob(lang, code, trained_data, all_words ):\n",
    "    \n",
    "    prob = 0\n",
    "    for word in code:\n",
    "        try:\n",
    "            if prob == 0:\n",
    "                prob = trained_data[lang][word]/all_words[word]\n",
    "            else:\n",
    "                prob = prob * trained_data[lang][word]/all_words[word]\n",
    "        except(KeyError):\n",
    "            continue\n",
    "            \n",
    "    return(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_prob(trained_data, all_words, code, langs):\n",
    "    \n",
    "    lang_chance = {}\n",
    "    \n",
    "    for lang in langs:\n",
    "        prob = calc_prob(lang, code, trained_data, all_words )\n",
    "        lang_chance[lang] = prob\n",
    "        \n",
    "    print(lang_chance)\n",
    "    return(max(lang_chance, key=lang_chance.get))\n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'javascript': 4.880673204007586e-11, 'swift': 1.4077064071157346e-13, 'python': 5.2493690582965744e-12, 'java': 6.779470893429329e-10, 'c++': 1.2337194191215784e-12, 'ruby': 2.229518268372761e-12, 'rust': 9.270360226680397e-13, 'c': 9.882278363673579e-10, 'scala': 2.9590204514369967e-13, 'r': 1.5028443250410055e-09, 'go': 2.1371336199803024e-09, 'mathematica': 1.1484656886326058e-09, 'kotlin': 5.800462090660877e-10, 'fortran': 2.2850776696018937e-12, 'julia': 3.168112881069258e-14, 'php': 4.9169746315203076e-08, 'matlab': 2.837713748455233e-08, 'haskell': 2.8644764595090476e-07, 'perl': 0.000509052708097724}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'perl'"
      ]
     },
     "execution_count": 957,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'test_data.txt'#enter here te file name (code.txt)\n",
    "code = read_the_file(filename)\n",
    "\n",
    "language_prob(trained_data, all_words, code, langs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
